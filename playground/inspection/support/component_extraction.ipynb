{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.io import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = [\"arduino\", \"netcard\", \"drawcore\"]\n",
    "source_folder = (\n",
    "    \"/media/egor/T7/vut_dp_project_workspace/assets/datasets/custom_structured/\"\n",
    ")\n",
    "\n",
    "mask_folder = \"/media/egor/T7/vut_dp_project_workspace/source/playground/inspection/support/exports/_masks/\"\n",
    "original_folder = \"/media/egor/T7/vut_dp_project_workspace/source/playground/inspection/support/exports/_originals/\"\n",
    "export_folder = \"/media/egor/T7/vut_dp_project_workspace/source/playground/inspection/support/exports/\"\n",
    "\n",
    "extract_colors = [\n",
    "    [np.array([255, 255, 0], np.uint8), \"cap_polar\"],  # RGB, cap. (polar)\n",
    "    [np.array([255, 0, 0], np.uint8), \"resister\"],  # RGB, resister\n",
    "    [np.array([0, 255, 0], np.uint8), \"cap_nonpolar\"],  # RGB, cap.\n",
    "    [np.array([0, 0, 255], np.uint8), \"missing\"],  # RGB, miss\n",
    "    [np.array([60, 120, 120], np.uint8), \"led\"],  # RGB, led\n",
    "    [np.array([100, 180, 120], np.uint8), \"ic\"],  # RGB, IC\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align(im, template):\n",
    "    # use ORB to detect keypoints and extract (binary) local\n",
    "    # invariant features\n",
    "    orb = cv2.ORB_create(1000)\n",
    "\n",
    "    (kpsA, descsA) = orb.detectAndCompute(im, None)\n",
    "    (kpsB, descsB) = orb.detectAndCompute(template, None)\n",
    "\n",
    "    # match the features\n",
    "    method = cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING\n",
    "    matcher = cv2.DescriptorMatcher_create(method)\n",
    "    matches = matcher.match(descsA, descsB, None)\n",
    "\n",
    "    # sort the matches by their distance (the smaller the distance,\n",
    "    # the \"more similar\" the features are)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    # keep only the top matches\n",
    "    keep = int(len(matches) * 0.5)\n",
    "    matches = matches[:keep]\n",
    "\n",
    "    # check to see if we should visualize the matched keypoints\n",
    "    # matchedVis = cv2.drawMatches(im, kpsA, template, kpsB, matches, None)\n",
    "    # matchedVis = imutils.resize(matchedVis, width=1000)\n",
    "    # imshow(matchedVis)\n",
    "\n",
    "    # allocate memory for the keypoints (x, y)-coordinates from the\n",
    "    # top matches -- we'll use these coordinates to compute our\n",
    "    # homography matrix\n",
    "    ptsA = np.zeros((len(matches), 2), dtype=\"float\")\n",
    "    ptsB = np.zeros((len(matches), 2), dtype=\"float\")\n",
    "    # loop over the top matches\n",
    "    for i, m in enumerate(matches):\n",
    "        # indicate that the two keypoints in the respective images\n",
    "        # map to each other\n",
    "        ptsA[i] = kpsA[m.queryIdx].pt\n",
    "        ptsB[i] = kpsB[m.trainIdx].pt\n",
    "\n",
    "    # compute the homography matrix between the two sets of matched\n",
    "    # points\n",
    "    (H, mask) = cv2.findHomography(ptsA, ptsB, method=cv2.RANSAC)\n",
    "    # use the homography matrix to align the images\n",
    "    (h, w) = template.shape[:2]\n",
    "    im = cv2.warpPerspective(im, H, (w, h))\n",
    "    # return the aligned image\n",
    "    return im\n",
    "\n",
    "\n",
    "def cut(im, value):\n",
    "    t = value[cv2.CC_STAT_TOP]\n",
    "    l = value[cv2.CC_STAT_LEFT]\n",
    "\n",
    "    w = value[cv2.CC_STAT_WIDTH]\n",
    "    h = value[cv2.CC_STAT_HEIGHT]\n",
    "\n",
    "    return im[t: t + h, l: l + w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: 27_arduino_um_16mm_f8_5299\n",
      "processing: 28_arduino_um_16mm_f8_4750\n",
      "processing: 29_arduino_um_16mm_f8_6023\n",
      "processing: 21_netcard_um_16mm_f8_4320\n",
      "processing: 22_netcard_um_16mm_f8_3101\n",
      "processing: 23_netcard_um_16mm_f8_5014\n",
      "processing: 24_drawcore_um_16mm_f8_4580\n",
      "processing: 25_drawcore_um_16mm_f8_3110\n",
      "processing: 26_drawcore_um_16mm_f8_5236\n"
     ]
    }
   ],
   "source": [
    "def extract(im, color: list[int], masked: np.ndarray):\n",
    "    mask = cv2.inRange(masked, color, color)\n",
    "    analysis = cv2.connectedComponentsWithStats(mask, cv2.CV_32S)\n",
    "    (_, _, values, _) = analysis\n",
    "\n",
    "    chunks = []\n",
    "    im = np.multiply(align(im, original), mask)\n",
    "    for i in range(1, len(values)):\n",
    "        chunks.append(255 - cut(im, values[i]))\n",
    "    return chunks\n",
    "\n",
    "\n",
    "try:\n",
    "    os.mkdir(export_folder)\n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "\n",
    "for obj in objects:\n",
    "    masked = cv2.cvtColor(  # Image with mask\n",
    "        cv2.imread(f\"{mask_folder}/{obj}.png\"),\n",
    "        cv2.COLOR_BGR2RGB,\n",
    "    )\n",
    "    original = cv2.cvtColor(  # Source image used for mask\n",
    "        cv2.imread(f\"{original_folder}/{obj}.bmp\"),\n",
    "        cv2.COLOR_RGB2GRAY,\n",
    "    )\n",
    "\n",
    "    for fld in os.listdir(source_folder):\n",
    "        if \"um\" in fld and obj in fld:\n",
    "            print(f\"processing: {fld}\")\n",
    "            for f in os.listdir(f\"{source_folder}/{fld}\"):\n",
    "                im = cv2.cvtColor(  # Image to extract components\n",
    "                    cv2.imread(f\"{source_folder}/{fld}/{f}\"),\n",
    "                    cv2.COLOR_RGB2GRAY,\n",
    "                )\n",
    "                for color, lbl in extract_colors:\n",
    "                    try:\n",
    "                        os.mkdir(f\"{export_folder}/{lbl}\")\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                    chunks = extract(im, color, masked)\n",
    "                    for i, chunk in enumerate(chunks):\n",
    "                        cv2.imwrite(f\"{export_folder}/{lbl}/{fld}__{f}__{i}.bmp\", chunk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
